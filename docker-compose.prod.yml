version: "3.8"

services:
  mysqldb:
    build: ./backend/db
    container_name: mysqldb
    env_file:
      - "./backend/db/.env"
    ports:
      - "3307:3307"
    volumes:
      - mysql-data:/var/lib/mysql
    networks:
      - app-network

  backend:
    build:
      context: ./backend/django_backend
      dockerfile: Dockerfile
    container_name: backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./backend/django_backend/static:/app/static
      - ./backend/django_backend/media:/app/media
    restart: always
    depends_on:
      - mysqldb
    command: bash -c "
      python wait_mysql.py &&
      python manage.py makemigrations &&
      python manage.py migrate &&
      python manage.py collectstatic --noinput &&
      gunicorn --bind 0.0.0.0:8000 django_backend.wsgi:application
      "
    networks:
      - app-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "3001:3001"
    volumes:
      - /frontend/node_modules
      - build_folder:/frontend/dist
    networks:
      - app-network

  nginx:
    build: ./nginx
    container_name: nginx
    ports:
      - 80:80
      - 443:443
    restart: always
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/conf.d/nginx.conf
      - build_folder:/var/www/frontend
      - ./nginx/log:/var/log/nginx 
    depends_on:
      - backend
      - frontend
    networks:
      - app-network
    command: '/bin/sh -c ''while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g "daemon off;"'''

  redis_container:
    image: redis:latest
    container_name: redis
    environment:
      - TZ=Asia/Seoul
    ports:
      - "6379:6379"
    volumes:
      - ./backend/redis/data:/data
      - ./backend/redis/conf/redis.conf:/usr/local/conf/redis.conf
    depends_on:
      - backend
    labels:
      - "name=redis"
      - "mode=standalone"
    restart: always
    command: redis-server /usr/local/conf/redis.conf
    networks:
      - app-network

  # prometheus:
  #   image: prom/prometheus:v2.45.6
  #   container_name: prometheus
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./backend/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
  #   command:
  #     - "--config.file=/etc/prometheus/prometheus.yml"
  # #   networks:
  # #     - app-network

  # grafana:
  #   image: grafana/grafana:9.5.20
  #   container_name: grafana
  #   volumes:
  #     - ./backend/grafana:/etc/grafana/provisioning
  #     - ./backend/grafana/data:/var/lib/grafana
  #   ports:
  #     - "3000:3000"
  # #   networks:
  #     - app-network

  celery_worker:
    restart: always
    build:
      context: ./backend/django_backend
      dockerfile: Dockerfile
    command: "celery -A django_backend worker --loglevel=info"
    volumes:
      - ./backend:/app
    environment:
      - DJANGO_SETTINGS_MODULE=django_backend.settings
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672/
      - TZ=Asia/Seoul
    depends_on:
      - rabbitmq
    networks:
      - app-network

  flower:
    image: mher/flower
    environment:
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672/
      - FLOWER_PORT=5555
      - TZ=Asia/Seoul
    ports:
      - 5555:5555
    networks:
      - app-network

  rabbitmq:
    container_name: rabbitmq
    image: rabbitmq:3.7.14-management-alpine
    environment:
      - RABBITMQ_USER=guest
      - RABBITMQ_PASSWORD=guest
      - TZ=Asia/Seoul
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - .:/code
    networks:
      - app-network
      
  elasticsearch:
    build:
      context: ./backend/docker-elk/elasticsearch/
      args:
        ELASTIC_VERSION: 8.5.2
    volumes:
      - ./backend/docker-elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - elasticsearch:/usr/share/elasticsearch/data:Z
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      node.name: elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - elk
    restart: unless-stopped

  logstash:
    build:
      context: ./backend/docker-elk/logstash/
      args:
        ELASTIC_VERSION: 8.5.2
    volumes:
      - ./backend/docker-elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./backend/docker-elk/logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    build:
      context: ./backend/docker-elk/kibana/
      args:
        ELASTIC_VERSION: 8.5.2
    volumes:
      - ./backend/docker-elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - 5601:5601
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch
    restart: unless-stopped

  filebeat:
    build:
      context: ./backend/docker-elk/filebeat/
      args:
        ELASTIC_VERSION: 8.5.2
    entrypoint: "filebeat -e -strict.perms=false"
    volumes:
      - ./backend/docker-elk/filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - ./nginx/log:/var/log/nginx  # Ensure the correct path
    depends_on:
      - logstash
      - elasticsearch
      - kibana
    networks:
      - elk

volumes:
  mysql-data:
  redis-data:
  build_folder: null
  elasticsearch:

networks:
  app-network:
    driver: bridge
  elk:
    driver: bridge